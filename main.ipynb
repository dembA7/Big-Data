{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de Modelos Inteligentes Usando PySpark y MLLib\n",
    "\n",
    "### Arturo Cristián Díaz López\n",
    "### Instituto Tecnológico y de Estudios Superiores de Monterrey\n",
    "### 29-Oct-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En este proyecto, se ha empleado el dataset Fashion MNIST con el fin de construir un modelo de clasificación de imágenes de ropa y accesorios. Este dataset ha sido seleccionado debido a su popularidad en tareas de clasificación de imágenes, así como su similitud estructural con el clásico MNIST, pero con un mayor desafío visual al contener diez categorías de productos de moda. Este reporte resume las etapas clave del proyecto, incluyendo la visualización del dataset en Tableau, el desarrollo de un modelo en PySpark y su evaluación final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "El dataset Fashion MNIST contiene imágenes en escala de grises de 28x28 píxeles de 10 clases de artículos de moda. Cada imagen está etiquetada con un número de clase correspondiente a un tipo específico de artículo.\n",
    "\n",
    "### Estructura\n",
    "\n",
    "El dataset cuenta con las siguientes 10 clases, pertenecientes a una categoría de artículo de moda:\n",
    "\n",
    "- **0.** T-shirt\n",
    "- **1.** Trouser\n",
    "- **2.** Pullover\n",
    "- **3.** Dress\n",
    "- **4.** Coat\n",
    "- **5.** Sandal\n",
    "- **6.** Shirt\n",
    "- **7.** Sneaker\n",
    "- **8.** Bag\n",
    "- **9.** Ankle boot\n",
    "\n",
    "### Visualización\n",
    "\n",
    "Para mejorar la comprensión de las características visuales del dataset, se realizó una visualización en Tableau, explorando la distribución y las características de las imágenes en cada categoría. En esta visualización se observan diferencias entre clases. El siguiente código en Python muestra cómo se transformó el dataset para realizar una visualización en Tableau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "\n",
    "# Convertir de wide a long format\n",
    "df_long = df.melt(id_vars=[\"label\"], \n",
    "                  var_name=\"pixel\", \n",
    "                  value_name=\"intensity\")\n",
    "\n",
    "# Extraer las coordenadas x, y a partir del número del píxel\n",
    "df_long['x'] = df_long['pixel'].str.extract(r'(\\d+)').astype(int) % 28\n",
    "df_long['y'] = df_long['pixel'].str.extract(r'(\\d+)').astype(int) // 28\n",
    "\n",
    "# Guardar en un nuevo CSV\n",
    "df_long.to_csv('data/fashion_mnist_long.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El anterior código permitió obtener un archivo con datos fácilmente cargables en Tableau, aplicación que permitió generar visualizaciones a través del siguiente proceso:\n",
    "\n",
    "1. **Carga de datos**: El archivo generado `fashion_mnist_long.csv` fue importado a Tableau.\n",
    "2. **Preparación de datos**: Las coordenadas `x` y `y` se usaron para representar visualmente cada píxel, mientras que la columna `intensity` determinó la intensidad de color.\n",
    "3. **Exploración por categorías**: Se utilizó la columna `label` para filtrar y analizar cada clase de artículo de moda de forma individual.\n",
    "\n",
    "A continuación, se presentan las visualizaciones generadas en la aplicación antes mencionada:\n",
    "\n",
    "![Dashboard0](./assets/Dashboard0.png)\n",
    "\n",
    "![Dashboard1](./assets/Dashboard1.png)\n",
    "\n",
    "![Dashboard2](./assets/Dashboard2.png)\n",
    "\n",
    "![Dashboard3](./assets/Dashboard3.png)\n",
    "\n",
    "![DashboardAll](./assets//DashboardAll.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, se realizó una visualización para verificar el número de ítems por clase. Esta visualización permitió encontrar que las clases se encuentran distribuidas equitativamente para todas las imágenes.\n",
    "\n",
    "![DashboardClasses](./assets/ClassesDistribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "El modelo seleccionado fue un modelo de Random Forest Classifier para la clasificación de imágenes en el conjunto de datos de Fashion MNIST. Este modelo es una elección popular para tareas de clasificación debido a su capacidad de manejar grandes conjuntos de datos y su flexibilidad para ajustarse a distintos tipos de problemas.\n",
    "\n",
    "### Implementación en Apache Spark\n",
    "\n",
    "El modelo fue implementado usando PySpark, la interfaz Python de Apache Spark. El Random Forest fue elegido por su capacidad de evitar el sobreajuste y por su buen rendimiento en entornos de datos complejos. La elección de PySpark permitió un manejo eficiente del volumen de datos y del entrenamiento en paralelo, logrando un modelo escalable y robusto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y preparación de datos\n",
    "\n",
    "1. Configuración de Spark: Se estableció una sesión de Spark optimizada para el manejo de datos en paralelo, asignando memoria suficiente para la carga y el procesamiento del conjunto de datos.\n",
    "\n",
    "2. Carga y Preparación de Datos: El conjunto de entrenamiento se almacenó en formato Parquet y se particionó en 100 bloques, mejorando así la eficiencia del entrenamiento distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Creo mi sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fashion MNIST Data Preparation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Cargo los datos\n",
    "train_data = spark.read.csv(\"data/fashion-mnist_train.csv\", header=True, inferSchema=True)\n",
    "test_data = spark.read.csv(\"data/fashion-mnist_test.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Preparo las columnas de características\n",
    "feature_columns = [f\"pixel{i}\" for i in range(1, 785)]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "\n",
    "# Transformo los datos\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Selecciono las columnas relevantes\n",
    "train_data = train_data.select(\"label\", \"features\")\n",
    "test_data = test_data.select(\"label\", \"features\")\n",
    "\n",
    "# Guardo los datos preparados en formato Parquet\n",
    "train_data.write.mode('overwrite').parquet(\"data/prepared_train_data.parquet\")\n",
    "test_data.write.mode('overwrite').parquet(\"data/prepared_test_data.parquet\")\n",
    "\n",
    "# Muestro las primeras filas del DataFrame modificado\n",
    "train_data.select(\"label\", \"features\").show(5)\n",
    "\n",
    "# Detengo la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y guardado\n",
    "\n",
    "3. El clasificador se entrenó utilizando 100 árboles en el bosque aleatorio, configurado para equilibrar la precisión y la rapidez.\n",
    "\n",
    "4. El modelo entrenado se guardó para su evaluación y aplicación en futuras predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Creo mi sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fashion MNIST Model Training\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.memory\", \"5g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Cargo los datos preparados\n",
    "train_data = spark.read.parquet(\"data/prepared_train_data.parquet\").repartition(100)\n",
    "\n",
    "# Entreno el modelo\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Guardo el modelo\n",
    "model.save(\"models/fashion_mnist_rf_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "La evaluación del modelo se llevó a cabo utilizando métricas estándar de clasificación multiclase. El modelo fue probado en el conjunto de datos de prueba, aplicando el modelo entrenado para generar predicciones sobre cada clase de Fashion MNIST.\n",
    "\n",
    "Se cargaron los datos de prueba y el modelo entrenado. Los datos de prueba fueron transformados para obtener predicciones y probabilidades asociadas a cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, concat_ws\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "# Inicializo Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fashion MNIST Model Evaluator\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.memory\", \"5g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Defino un UDF para convertir un Vector a un Array\n",
    "def vector_to_array(vector):\n",
    "    return vector.toArray().tolist() if isinstance(vector, Vector) else []\n",
    "\n",
    "# Cargo datos de prueba\n",
    "test_data = spark.read.parquet(\"data/prepared_test_data.parquet\")\n",
    "\n",
    "# Cargo el modelo entrenado\n",
    "model = RandomForestClassificationModel.load(\"models/fashion_mnist_rf_model\")\n",
    "\n",
    "# Realizo predicciones\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evalúo el modelo\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Imprimo las métricas del modelo\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1_score}\")\n",
    "\n",
    "# Guardo las métricas en un archivo de texto\n",
    "with open(\"model_metrics.txt\", \"w\") as metrics_file:\n",
    "    metrics_file.write(f\"Accuracy: {accuracy}\\n\")\n",
    "    metrics_file.write(f\"Precision: {precision}\\n\")\n",
    "    metrics_file.write(f\"Recall: {recall}\\n\")\n",
    "    metrics_file.write(f\"F1-Score: {f1_score}\\n\")\n",
    "\n",
    "# Convierte 'features', 'rawPrediction', y 'probability' a arrays\n",
    "\n",
    "vector_to_array_udf = udf(vector_to_array, ArrayType(DoubleType()))\n",
    "predictions = predictions.withColumn(\"features\", vector_to_array_udf(col(\"features\"))) \\\n",
    "                         .withColumn(\"rawPrediction\", vector_to_array_udf(col(\"rawPrediction\"))) \\\n",
    "                         .withColumn(\"probability\", vector_to_array_udf(col(\"probability\")))\n",
    "\n",
    "# Convertir columnas de arrays a cadenas separadas por comas\n",
    "predictions = predictions.withColumn(\"features\", concat_ws(\",\", col(\"features\"))) \\\n",
    "                         .withColumn(\"rawPrediction\", concat_ws(\",\", col(\"rawPrediction\"))) \\\n",
    "                         .withColumn(\"probability\", concat_ws(\",\", col(\"probability\")))\n",
    "\n",
    "# Guardo las predicciones en un archivo CSV\n",
    "predictions.select(\"label\", \"prediction\", \"features\", \"rawPrediction\", \"probability\").write.mode(\"overwrite\").csv(\"predictions.csv\", header=True)\n",
    "\n",
    "# Cierro la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Evaluación\n",
    "\n",
    "1. **Accuracy**:  \n",
    "   Medida del porcentaje de predicciones correctas realizadas por el modelo.  \n",
    "   **Valor obtenido**: 0.7648  \n",
    "\n",
    "2. **Weighted Precision**:  \n",
    "   Evalúa la precisión general del modelo ponderada por el número de muestras en cada clase.  \n",
    "   **Valor obtenido**: 0.7907  \n",
    "\n",
    "3. **Weighted Recall**:  \n",
    "   Calcula el porcentaje de predicciones correctas sobre el total de instancias verdaderas por clase.  \n",
    "   **Valor obtenido**: 0.7648  \n",
    "\n",
    "4. **F1-Score**:  \n",
    "   Una medida combinada que equilibra precisión y recall, ponderada por el soporte de cada clase.  \n",
    "   **Valor obtenido**: 0.7434  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Se calcularon y almacenaron las métricas de evaluación, que son indicativas de un rendimiento aceptable del modelo sobre el conjunto de datos de prueba. Los resultados pueden encontrarse [aquí](./results/model_metrics.txt).\n",
    "\n",
    "### Almacenamiento de predicciones\n",
    "\n",
    "Las predicciones, junto con sus probabilidades y características originales, fueron exportadas a un archivo CSV para un análisis más detallado y posible visualización de resultados. Las predicciones hechas por el modelo pueden encontrarse en este [directorio](./predictions/).\n",
    "\n",
    "Este enfoque evaluativo permite identificar el rendimiento global del modelo y verificar la eficacia de sus predicciones en un conjunto de datos nunca antes visto, asegurando así su capacidad de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "En conclusión, el modelo de clasificación desarrollado con el dataset Fashion MNIST ha demostrado una capacidad razonable para identificar las diferentes categorías de prendas y accesorios. La visualización en Tableau contribuyó al análisis exploratorio y facilitó una mejor comprensión de las características distintivas de cada clase. A través del uso de PySpark, se logró procesar grandes volúmenes de datos de manera eficiente, y se ha dejado abierta la posibilidad de optimizaciones futuras en función de los resultados obtenidos en la evaluación. Este proyecto sirve como una base sólida para el desarrollo de sistemas de clasificación más complejos en el campo de la moda y otras aplicaciones de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "\n",
    "1. Zalando. *Fashion MNIST Dataset*.  \n",
    "   [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "2. Apache Spark. *Apache Spark Documentation*.  \n",
    "   [https://spark.apache.org/docs/latest/](https://spark.apache.org/docs/latest/)\n",
    "\n",
    "3. Apache Spark. *PySpark Documentation*.  \n",
    "   [https://spark.apache.org/docs/latest/api/python/](https://spark.apache.org/docs/latest/api/python/)\n",
    "\n",
    "4. Apache Spark. *Machine Learning Pipelines*.  \n",
    "   [https://spark.apache.org/docs/latest/ml-guide.html](https://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n",
    "5. Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32.  \n",
    "   [https://link.springer.com/article/10.1023/A:1010933404324](https://link.springer.com/article/10.1023/A:1010933404324)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
